<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Recent &amp; Upcoming Talks on Pedro Mercado</title>
    <link>https://melopeo.github.io/talk/</link>
    <description>Recent content in Recent &amp; Upcoming Talks on Pedro Mercado</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/talk/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Clustering Signed Networks with the Geometric Mean of Laplacians</title>
      <link>https://melopeo.github.io/talk/gamm-2016/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0100</pubDate>
      
      <guid>https://melopeo.github.io/talk/gamm-2016/</guid>
      <description>&lt;p&gt;We define a signed network $G^{\pm}$ as a pair of graphs $G^{\pm}=(G^+, G^-)$, where $G^+=(V,E^+)$ encodes positive (friendship) relations and $G^-=(V,E^-)$ encodes negative (enmity) ones.
In this talk we discuss major drawbacks of popular extensions of spectral clustering to signed networks.
Our analysis shows that in expectation under the Stochastic Block Model (SBM) existing approaches do not recover ground-truth clusters even when either $G^+$ or $G^-$ contains no noise.&lt;/p&gt;

&lt;p&gt;This problem arises as existing approaches merge the informations from $G^+$ and $G^-$ through a form of arithmetic mean of Laplacians or adjacencies of the positive and negative part.
We propose to use the geometric mean of the Laplacian matrix $L$ of $G^+$  and the signless Laplacian $Q$ of $G^-$, defined by
 $$ L \# Q  = L^\frac{1}{2} ( L^{-\frac{1}{2}} Q L^{-\frac{1}{2}} )^\frac{1}{2} {L}^\frac{1}{2}$$&lt;/p&gt;

&lt;p&gt;We show that in expectation under the SBM the extremal eigenvectors of the matrix $L \# Q$ recover ground-truth clusters in any reasonable clustering setting, outperforming existing approaches.&lt;/p&gt;

&lt;p&gt;We propose a numerical method to efficiently compute some extremal eigenvectors of the geometric mean $L \# Q$ without ever computing $L \# Q$ itself. Our algorithm is based on the inverse power method and the extended Krylov subspace technique, and applies to the geometric mean $A \# B$ of a generic pair of positive definite matrices $A$ and $B$.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Clustering Signed Networks with the Geometric Mean of Laplacians</title>
      <link>https://melopeo.github.io/talk/gcpr-2017/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0100</pubDate>
      
      <guid>https://melopeo.github.io/talk/gcpr-2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Community Detection in Networks via Nonlinear Modularity Eigenvectors</title>
      <link>https://melopeo.github.io/talk/siam-an-2017/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0100</pubDate>
      
      <guid>https://melopeo.github.io/talk/siam-an-2017/</guid>
      <description>&lt;p&gt;Community identification in networks is a central problem arising in many scientific areas.
The modularity function $Q$ is an effective measure of the quality of a community, being
defined as a set of nodes having high modularity.
Community detection thus boils down to the combinatorial optimization problem of locating sets of nodes maximizing $Q$.
This problem is known to be NP-hard thus posing the need of approximation techniques which are typically based on
a linear relaxation of $Q$, induced by the spectrum of the modularity matrix $\mathcal M$.&lt;/p&gt;

&lt;p&gt;In this work we propose a nonlinear relaxation which is based on the spectrum of a nonlinear modularity operator $\mathcal M$.
We show that extremal eigenvalues of $\mathcal M$
satisfy a tight Cheeger-type inequality providing
an exact relaxation of the modularity function $Q$,however
at a price of being more challenging to be computed than
the extremal eigenvalues of the linear counterpart based on $\mathcal M$.
We propose a general optimization scheme for the computation of the extremal eigenvalues of $\mathcal M$,
named Generalized RatioDCA, and we show monotonic ascent and
convergence of the method to a critical value. Finally, we
present extensive evaluations on synthetic and real-world
datasets showing that our method is competitive to the
state of the art.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Matrix Means for Signed and Multilayer Graph Clustering</title>
      <link>https://melopeo.github.io/talk/alan-turing-2018/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0100</pubDate>
      
      <guid>https://melopeo.github.io/talk/alan-turing-2018/</guid>
      <description>&lt;p&gt;In this talk we present an extension of spectral clustering for the case when different kinds of interactions are present. We study suitable matrix functions to merge information that comes from different kinds of interactions encoded in multilayer graphs, and their effect in cluster identification. We consider a one-parameter family of matrix functions, known as matrix power means, and show that different means identify clusters under different settings of the stochastic block model in expectation. For instance, we show that a limit case identifies clusters if at least one layer is informative and the remaining layers are potentially just noise.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Matrix Means for Signed and Multilayer Graph Clustering</title>
      <link>https://melopeo.github.io/talk/iciam-2019/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0100</pubDate>
      
      <guid>https://melopeo.github.io/talk/iciam-2019/</guid>
      <description>&lt;p&gt;In this talk we present an extension of spectral clustering for the case when different kinds of interactions are present. We study suitable matrix functions to merge information that comes from different kinds of interactions encoded in multilayer graphs, and their effect in cluster identification. We consider a one-parameter family of matrix functions, known as matrix power means, and show that different means identify clusters under different settings of the stochastic block model in expectation. For instance, we show that a limit case identifies clusters if at least one layer is informative and the remaining layers are potentially just noise.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Matrix Means for Signed and Multilayer Graph Clustering</title>
      <link>https://melopeo.github.io/talk/siam-ala-2018/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0100</pubDate>
      
      <guid>https://melopeo.github.io/talk/siam-ala-2018/</guid>
      <description>&lt;p&gt;We study suitable matrix functions to merge information that comes from different kinds of interactions encoded in multilayer graphs, and its effects in cluster identification.
We consider a family of matrix functions, known as power means,
and show that different means identify clusters under different settings of the stochastic block model.
For instance, we show that a limit case identifies clusters if at least one layer is informative and remaining
layers are potentially just noise.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
